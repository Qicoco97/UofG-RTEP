{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Video-based Baby Monitor Overview The baby monitor is a contactless, video-based baby monitor. This project primarily uses a C++ implementation of the MIT video enlargement algorithm that runs on a Raspberry Pi 3 Model B and is easily extensible. You can setup your own baby monitor that raises an alarm if your infant stops moving. Getting Started The baby monitor consists of two parts: baby monitor software and some simple hardware. Learn how to use and recreate your own monitor in the following section. Software To install prerequisites, build the software, or learn more about the software architecture, see Software Installation Guide . Hardware To learn more about the hardware materials we used, and how we build our setup, check out the Hardware Setup Guide . Video Walkthroughs ==TODO: \u63d2\u5165\u6211\u4eec\u7684\u5ba3\u4f20\u89c6\u9891==","title":"Home"},{"location":"#video-based-baby-monitor-overview","text":"The baby monitor is a contactless, video-based baby monitor. This project primarily uses a C++ implementation of the MIT video enlargement algorithm that runs on a Raspberry Pi 3 Model B and is easily extensible. You can setup your own baby monitor that raises an alarm if your infant stops moving.","title":"Video-based Baby Monitor Overview"},{"location":"#getting-started","text":"The baby monitor consists of two parts: baby monitor software and some simple hardware. Learn how to use and recreate your own monitor in the following section.","title":"Getting Started"},{"location":"#software","text":"To install prerequisites, build the software, or learn more about the software architecture, see Software Installation Guide .","title":"Software"},{"location":"#hardware","text":"To learn more about the hardware materials we used, and how we build our setup, check out the Hardware Setup Guide .","title":"Hardware"},{"location":"#video-walkthroughs","text":"==TODO: \u63d2\u5165\u6211\u4eec\u7684\u5ba3\u4f20\u89c6\u9891==","title":"Video Walkthroughs"},{"location":"setup/config/","text":"Configuration The configuration of the baby monitor uses a file usually located at /etc/babymonitor/config.ini . Its format is the same as that of an INI file: each line represents a configuration value, and directives are grouped in square brackets. Comments are separated by ; until the end of the line. Input/Output The [io] section of the file configures the input to the baby monitor. The input directive specifies that the magnifier should look for a video file instead of a live camera input, while the camera directive selects the camera device to use (e.g. camera=0 means use /dev/video0 as input). File input exists only as a demonstration or debugging feature. If you change the input, you must also specify the fps parameter to match the input. For file input there is only one fps setting as frames are never dropped, whereas for camera input, to reduce latency you must specify the frames per second for both the full and cropped frame sizes (approximately 3 times the full frame size fps). The latter values \u200b\u200bdepend on the speedo ft and CPU on which baby monitor run. Note that when using input files with less than 15 fps, crop_fps should be set to the fps value of the input file to ensure correct calculation of the bandpass frequencies. time_to_alarm determines the number of system time seconds the baby monitor waits before playing the alarm sound through the audio port after it stops detecting motion. Cropping The [cropping] section controls motion-based adaptive cropping, focusing the upscaling process on a smaller region of interest (ROI) where the most motion occurs, thus reducing CPU load. The different parameters affect the latency of the detection, as they control the number of \"slow\" frames (completely uncropped). The best values \u200b\u200bfor the parameters depend on the target CPU. If you are running on something other than a Pi, and the device is powerful enough, you can also disable cropping altogether. The default configuration will update the crop approximately every minute. Motion & Magnification The [motion] and [magnification] sections control the motion detection and video magnification algorithms respectively. These parameters depend on the environment in which the baby monitor is deployed, such as lighting conditions and contrast of the baby. You may need to calibrate erode_dim and dilate_dim , which are used to determine where to crop the video, as well as diff_threshold and pixel_threshold , which determine the threshold used to judge how much a pixel changes, and the number of moving pixels required before classifying motion as motion rather than noise. Specifically, diff_threshold specifies how much a grayscale pixel (value between 0 and 255) needs to change before it is marked as changed. For example, if diff_threshold is 30, the difference between pixels must be equal to or greater than 30 to be marked as changed. The higher this threshold, the more different the pixels need to be labeled. pixel_threshold defines a hard limit on the number of pixels that need to be marked as changed before a motion value is output. This effectively sets the noise cutoff for determining whether the baby is breathing. For example, if pixel_threshold is set to 100, the algorithm must detect a change of more than 100 pixels before registering any visible motion. If the threshold is not exceeded, no motion is reported. erode_dim specifies the dimension of the kernel used in the OpenCV erosion operation . This is used to minimize the changed pixels. That is, isolated pixels are removed, but when large groups of pixels are changed, those pixels are preserved. dilate_dim does the opposite, it takes pixels and dilates them. These two parameters are used to detect the area of \u200b\u200bthe frame where the baby is. First, the pixel differences are calculated, then a small erosion is applied to remove noise, and a large dilation is applied to roughly mark the area of \u200b\u200bmotion. Low Cutoff and High Cutoff define the range of the bandpass filter used during amplification. Specifically, video upscaling will attempt to amplify motion that occurs within this frequency range, while ignoring motion outside of this range. We have adjusted it so that it can capture the average breathing rat, but you may need to adjust it during calibration. See the section on calibration for more information. Debugging features The show_diff flag in [motion] will display a window where areas in the frame where motion was detected are highlighted in white. The show_magnification flag in [magnification] controls a window that shows just the output of the video magnification (it should look like a black and white image of the camera feed, with magnified motion). You can use these two flags to display the results of changes to the motion and magnification parameters. Finally, print_times in the [debug] section controls the printing of frame times to standard output, which you can use to calibrate FPS and latency settings when running on a device other than the Raspberry Pi. When starting Baby Monitor via systemd (automatically at boot or with systemctl start ), these features must be turned off. They are only useful when running Baby Monitor manually. Calibrating the Motion & Magnification algorithm Algorithm calibration is an iterative process with no right or wrong answer. We encourage you to experiment with various values \u200b\u200band combine them with the debugging feature to find the combination of parameters that works best for your environment. As a guideline, increasing the amplification and phase_threshold values \u200b\u200bincreases the amount of amplification applied to the input video. You should change these values \u200b\u200buntil you can clearly see the motion of your baby's breathing and there are no noticeable artifacts in other areas of the video. If you experience artifacts, lowering the phase_threshold while keeping the same amplification may help. You can see the effect of these parameters by setting show_magnification to true . As for the motion detection parameters, the main driving factor is the amount of noise. When detecting motion regions to be cropped, erode_dim and dilate_dim are used to adjust the size of the OpenCV kernels used for the erosion and dilation motion in order to first remove the noise and then significantly dilate the remaining motion signal to make the motion regions apparent. If your crib is in a very high contrast environment, you may also need to adjust these parameters. Generally speaking, for high contrast settings you want a higher erode_dim, and for low contrast settings you want a lower erode_dim. If you run with show_diff=true and you notice that too many parts of your input video are white, or that some completely irrelevant parts of the video are detected as motion (such as a flashing light), then you will want to increase erode_dim until the only parts of the video corresponding to your breathing baby are the largest white parts. The top image shows an example where the erosion dimension is too low for the amount of motion in the frame, while the bottom image shows a correctly calibrated frame. ==\u9700\u8981\u6362\u6210\u5b9e\u9645\u6d4b\u8bd5\u56fe== Once the calibration is complete you will want to make sure the pixel_threshold is set so that motion is only reported when you expect it, rather than constantly (which means you will need to remove noise). Ideally, you would see output like this in your terminal: [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 44 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 161 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 121 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 86 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 97 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 74 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 60 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 48 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 38 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 29 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 28 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 22 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz ==\u6362\u6210\u5b9e\u9645\u7684\u597d\u7684\u6d4b\u8bd5\u7ed3\u679c== There are clear periodic patterns that correspond to the movements. If your output looks more like this: [info] Pixel Movement: 921 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 736 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 666 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 663 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 1196 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 1235 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 1187 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 1115 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 959 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 744 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 611 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 468 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 371 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 307 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 270 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 234 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 197 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 179 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 164 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 239 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 733 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 686 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 667 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 607 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 544 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 499 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 434 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 396 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 375 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 389 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 305 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 269 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 1382 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 1086 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 1049 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 811 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 601 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 456 [info] Motion Estimate: 1.312346 Hz ==\u6362\u6210\u5b9e\u9645\u7684\u4e0d\u597d\u7684\u6d4b\u8bd5\u7ed3\u679c== You then need to adjust the pixel_threshold and diff_threshold until you see a peak, otherwise the pixel shift is 0.","title":"Software Configuration Parameters"},{"location":"setup/config/#configuration","text":"The configuration of the baby monitor uses a file usually located at /etc/babymonitor/config.ini . Its format is the same as that of an INI file: each line represents a configuration value, and directives are grouped in square brackets. Comments are separated by ; until the end of the line.","title":"Configuration"},{"location":"setup/config/#inputoutput","text":"The [io] section of the file configures the input to the baby monitor. The input directive specifies that the magnifier should look for a video file instead of a live camera input, while the camera directive selects the camera device to use (e.g. camera=0 means use /dev/video0 as input). File input exists only as a demonstration or debugging feature. If you change the input, you must also specify the fps parameter to match the input. For file input there is only one fps setting as frames are never dropped, whereas for camera input, to reduce latency you must specify the frames per second for both the full and cropped frame sizes (approximately 3 times the full frame size fps). The latter values \u200b\u200bdepend on the speedo ft and CPU on which baby monitor run. Note that when using input files with less than 15 fps, crop_fps should be set to the fps value of the input file to ensure correct calculation of the bandpass frequencies. time_to_alarm determines the number of system time seconds the baby monitor waits before playing the alarm sound through the audio port after it stops detecting motion.","title":"Input/Output"},{"location":"setup/config/#cropping","text":"The [cropping] section controls motion-based adaptive cropping, focusing the upscaling process on a smaller region of interest (ROI) where the most motion occurs, thus reducing CPU load. The different parameters affect the latency of the detection, as they control the number of \"slow\" frames (completely uncropped). The best values \u200b\u200bfor the parameters depend on the target CPU. If you are running on something other than a Pi, and the device is powerful enough, you can also disable cropping altogether. The default configuration will update the crop approximately every minute.","title":"Cropping"},{"location":"setup/config/#motion-magnification","text":"The [motion] and [magnification] sections control the motion detection and video magnification algorithms respectively. These parameters depend on the environment in which the baby monitor is deployed, such as lighting conditions and contrast of the baby. You may need to calibrate erode_dim and dilate_dim , which are used to determine where to crop the video, as well as diff_threshold and pixel_threshold , which determine the threshold used to judge how much a pixel changes, and the number of moving pixels required before classifying motion as motion rather than noise. Specifically, diff_threshold specifies how much a grayscale pixel (value between 0 and 255) needs to change before it is marked as changed. For example, if diff_threshold is 30, the difference between pixels must be equal to or greater than 30 to be marked as changed. The higher this threshold, the more different the pixels need to be labeled. pixel_threshold defines a hard limit on the number of pixels that need to be marked as changed before a motion value is output. This effectively sets the noise cutoff for determining whether the baby is breathing. For example, if pixel_threshold is set to 100, the algorithm must detect a change of more than 100 pixels before registering any visible motion. If the threshold is not exceeded, no motion is reported. erode_dim specifies the dimension of the kernel used in the OpenCV erosion operation . This is used to minimize the changed pixels. That is, isolated pixels are removed, but when large groups of pixels are changed, those pixels are preserved. dilate_dim does the opposite, it takes pixels and dilates them. These two parameters are used to detect the area of \u200b\u200bthe frame where the baby is. First, the pixel differences are calculated, then a small erosion is applied to remove noise, and a large dilation is applied to roughly mark the area of \u200b\u200bmotion. Low Cutoff and High Cutoff define the range of the bandpass filter used during amplification. Specifically, video upscaling will attempt to amplify motion that occurs within this frequency range, while ignoring motion outside of this range. We have adjusted it so that it can capture the average breathing rat, but you may need to adjust it during calibration. See the section on calibration for more information.","title":"Motion &amp; Magnification"},{"location":"setup/config/#debugging-features","text":"The show_diff flag in [motion] will display a window where areas in the frame where motion was detected are highlighted in white. The show_magnification flag in [magnification] controls a window that shows just the output of the video magnification (it should look like a black and white image of the camera feed, with magnified motion). You can use these two flags to display the results of changes to the motion and magnification parameters. Finally, print_times in the [debug] section controls the printing of frame times to standard output, which you can use to calibrate FPS and latency settings when running on a device other than the Raspberry Pi. When starting Baby Monitor via systemd (automatically at boot or with systemctl start ), these features must be turned off. They are only useful when running Baby Monitor manually.","title":"Debugging features"},{"location":"setup/config/#calibrating-the-motion-magnification-algorithm","text":"Algorithm calibration is an iterative process with no right or wrong answer. We encourage you to experiment with various values \u200b\u200band combine them with the debugging feature to find the combination of parameters that works best for your environment. As a guideline, increasing the amplification and phase_threshold values \u200b\u200bincreases the amount of amplification applied to the input video. You should change these values \u200b\u200buntil you can clearly see the motion of your baby's breathing and there are no noticeable artifacts in other areas of the video. If you experience artifacts, lowering the phase_threshold while keeping the same amplification may help. You can see the effect of these parameters by setting show_magnification to true . As for the motion detection parameters, the main driving factor is the amount of noise. When detecting motion regions to be cropped, erode_dim and dilate_dim are used to adjust the size of the OpenCV kernels used for the erosion and dilation motion in order to first remove the noise and then significantly dilate the remaining motion signal to make the motion regions apparent. If your crib is in a very high contrast environment, you may also need to adjust these parameters. Generally speaking, for high contrast settings you want a higher erode_dim, and for low contrast settings you want a lower erode_dim. If you run with show_diff=true and you notice that too many parts of your input video are white, or that some completely irrelevant parts of the video are detected as motion (such as a flashing light), then you will want to increase erode_dim until the only parts of the video corresponding to your breathing baby are the largest white parts. The top image shows an example where the erosion dimension is too low for the amount of motion in the frame, while the bottom image shows a correctly calibrated frame. ==\u9700\u8981\u6362\u6210\u5b9e\u9645\u6d4b\u8bd5\u56fe== Once the calibration is complete you will want to make sure the pixel_threshold is set so that motion is only reported when you expect it, rather than constantly (which means you will need to remove noise). Ideally, you would see output like this in your terminal: [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 44 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 161 [info] Motion Estimate: 1.219812 Hz [info] Pixel Movement: 121 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 86 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 97 [info] Motion Estimate: 0.841416 Hz [info] Pixel Movement: 74 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 60 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 48 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 38 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 29 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 28 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 22 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz [info] Pixel Movement: 0 [info] Motion Estimate: 0.839298 Hz ==\u6362\u6210\u5b9e\u9645\u7684\u597d\u7684\u6d4b\u8bd5\u7ed3\u679c== There are clear periodic patterns that correspond to the movements. If your output looks more like this: [info] Pixel Movement: 921 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 736 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 666 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 663 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 1196 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 1235 [info] Motion Estimate: 1.352046 Hz [info] Pixel Movement: 1187 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 1115 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 959 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 744 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 611 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 468 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 371 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 307 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 270 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 234 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 197 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 179 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 164 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 239 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 733 [info] Motion Estimate: 1.456389 Hz [info] Pixel Movement: 686 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 667 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 607 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 544 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 499 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 434 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 396 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 375 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 389 [info] Motion Estimate: 1.229389 Hz [info] Pixel Movement: 305 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 269 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 1382 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 1086 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 1049 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 811 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 601 [info] Motion Estimate: 1.312346 Hz [info] Pixel Movement: 456 [info] Motion Estimate: 1.312346 Hz ==\u6362\u6210\u5b9e\u9645\u7684\u4e0d\u597d\u7684\u6d4b\u8bd5\u7ed3\u679c== You then need to adjust the pixel_threshold and diff_threshold until you see a peak, otherwise the pixel shift is 0.","title":"Calibrating the Motion &amp; Magnification algorithm"},{"location":"setup/hw-setup/","text":"Hardare Setup Guide Figure: Hardware Block Diagram Baby monitors are relatively simple to construct and consist mainly of commercially available components. As shown above, there are 5 main hardware components, of which only 2 are customised. This page contains installation instructions for the baby monitor. What you'll need Raspberry Pi + Camera + configuration tools: Raspberry Pi 3 Model B 5V 2.5A Micro USB Power Supply Raspberry Pi NoIR Camera Module V2 1W IR LED MicroSD Card (we used a Class 10 16GB card, the faster the card the better) Flex Cable for Raspberry Pi Camera (12\") Speakers with 3.5mm input HDMI monitor USB Keyboard USB Mouse [optional] Raspberry Pi Heatsink (If you're worried about heat, you can stick these onto your Pi.) IR LED Circuit for low-light operation: [3x] 1N4001 diodes 1 ohm, 1W resistor [2x] 12\" Wires with pin headers Soldering iron Chassis: Access to a 3D printer (minimum build volume = 9.9\" L x 7.8\" W x 5.9\" H) to print the chassis Glue (any type of glue will will work, but hot glue is recommended for prototyping) Prerequisites Before starting our step-by-step guide, you should have installed the latest version of Raspbian on your SD card and made sure that your Pi boots properly. You also need to Enable Camera Module before you can connect the camera. Build Instructions Swap NoIR Camera Cable The 6-inch cable that came with the camera is too short. Please replace the short (6-inch) cable with a long (12-inch) cable. You can follow this guide provided by ModMyPi . In short, the NoIR camera has a push/pull tab on the back of the camera, just like the one on the Pi itself: Simply pull the black plastic tab out, remove the short cable and replace it with the long cable (make sure the blue plastic strip is facing up as shown), then push the plastic tab back in to secure the cable. 3D Printed Chassis Use of our chassis is optional but recommended to prevent young children from touching exposed electronic circuitry. Every cot is different, so our chassis does not include mounting brackets. If you have access to a MakerBot Replicator (5th Generation), you can simply download the .makerbot files for the case and cover onto your MakerBot Replicator and print. If you are using a different type of 3D printer, please keep reading. As mentioned above, printing a baby monitor requires a minimum volume of 9.9 inches (L) x 7.8 inches (W) x 5.9 inches (H). If you don't have a 3D printer with this build volume, you can use an online 3D printing service such as Shapeways or Sculpteo to print the baby monitor. The minimum print resolution is 0.015 inches. If you are using a Fused Filament Manufacturing type 3D printer, this means that your nozzle diameter needs to be 0.015 inches or less. Printers with lower print resolution (larger nozzle diameter) may work, but the Raspberry Pi may not fit in the chassis. We recommend Polylactic Acid (PLA) as the preferred printing material. Other plastics can be used, but if the coefficient of thermal expansion of the chosen plastic is greater than that of PLA, the Raspberry Pi may not fit into the chassis. Before proceeding, download the enclosure and cover 3D files. For instructions on orienting the 3D model in the printer build space, refer to the instruction manual that came with the 3D printer. Examples of chassis and cover mounting orientations are shown below. Case: Cover: In addition to placing the neck of the baby monitor flat on the build plate, you may also notice that the model is rotated around a vertical axis. This may be necessary to load the model into the 3D printer build space. If the build space is long enough to accommodate the baby monitor, rotation is optional. IR LED Circuit To provide sufficient illumination at night, we use infrared LEDs, which are invisible to the human eye but visible to the NoIR camera. The IR LEDs don't consume much power compared to the Raspberry Pi, so for simplicity we'll leave the IR LEDs on. To power the LEDs through the GPIO pins on the Pi, we built the circuit shown below. Figure: LED Schematic For simplicity and backward compatibility, we use the 5V power pin, which can provide up to 1.5A . According to our measurements, the forward voltage of the infrared LED is about 1.7~1.9V. Although their LED and ASA have a maximum current of 500MA, we decided to reduce the current to around 200MA to reduce heat and overall power consumption. To bridge the gap between 5V and 1.9V, we decided to use three 1N4001 diodes and a 1 ohm resistor in series with the IR LED. Therefore, the voltage across the IR LED is 5V - 0.2V - (3 * 0.9V) - 0.2V = 1.9V . The heat dissipation of each LED is 0.18W, and the heat dissipation of the resistor is 0.2W, both within the maximum ratings. The circuit should looking something like this: Assembly: Bring it all together Once you have all the hardware ready, you can start assembling. You can use any glue for this process, but we recommend hot glue for two main reasons. Hot glue dries quickly, so you don't need to wait long for the glue to dry. In addition, if you make a mistake, hot glue is removable. To remove dried hot glue, soak the hot glue in in rubbing (isopropyl) alcohol. Make sure everything is dry before reapplying the hot glue and powering up your Raspberry Pi. Throughout the T and build process, check to make sure all T and ports are still accessible through the holes in the int and baby monitor chassis. Insert the Raspberry Pi into the case. Once it is in place, make sure all ports are accessible (e.g., you can plug in the power supply). Next, use some hot glue to secure the Raspberry Pi in place and mount the camera to the Raspberry Pi. There are also screw holes on the Raspberry Pi that you can use if you prefer. ==\u66ff\u6362\u5b9e\u7269\u56fe== Glue the LED and camera to the front cover. ==\u66ff\u6362\u5b9e\u7269\u56fe== First, glue the NoIR camera into the camera hole. Make sure the camera is firmly seated and aligned with the chassis. Do not use too much glue or the camera will not fit into the main case. Always power on the Raspberry Pi and check the camera (e.g., using raspistill -v ) to make sure it is at the right angle and has a good field of view. If the angle is wrong, remove the hot glue and reposition it. ==\u66ff\u6362\u5b9e\u7269\u56fe== Next, glue an infrared LED light to the hole in the neck of the bedspread. It is at a 45-degree angle to the bedspread to illuminate the crib from the side and create more shadows in low-light environments. This will increase the contrast of the image and make it easier to detect motion. ==\u66ff\u6362\u5b9e\u7269\u56fe== After gluing them to the neck, it should look like this: ==\u66ff\u6362\u5b9e\u7269\u56fe== Connect the infrared LED wires to the GPIO pins of the Raspberry Pi as shown in the LED schematic. Place the cable into the chassis, being careful not to wrinkle or strain it. ==\u66ff\u6362\u5b9e\u7269\u56fe== Once everything is tucked in place, hot glue the edges where the two pieces meet to seal them in place. ==\u66ff\u6362\u5b9e\u7269\u56fe==","title":"Hardware Setup Instructions"},{"location":"setup/hw-setup/#hardare-setup-guide","text":"Figure: Hardware Block Diagram Baby monitors are relatively simple to construct and consist mainly of commercially available components. As shown above, there are 5 main hardware components, of which only 2 are customised. This page contains installation instructions for the baby monitor.","title":"Hardare Setup Guide"},{"location":"setup/hw-setup/#what-youll-need","text":"Raspberry Pi + Camera + configuration tools: Raspberry Pi 3 Model B 5V 2.5A Micro USB Power Supply Raspberry Pi NoIR Camera Module V2 1W IR LED MicroSD Card (we used a Class 10 16GB card, the faster the card the better) Flex Cable for Raspberry Pi Camera (12\") Speakers with 3.5mm input HDMI monitor USB Keyboard USB Mouse [optional] Raspberry Pi Heatsink (If you're worried about heat, you can stick these onto your Pi.) IR LED Circuit for low-light operation: [3x] 1N4001 diodes 1 ohm, 1W resistor [2x] 12\" Wires with pin headers Soldering iron Chassis: Access to a 3D printer (minimum build volume = 9.9\" L x 7.8\" W x 5.9\" H) to print the chassis Glue (any type of glue will will work, but hot glue is recommended for prototyping)","title":"What you'll need"},{"location":"setup/hw-setup/#prerequisites","text":"Before starting our step-by-step guide, you should have installed the latest version of Raspbian on your SD card and made sure that your Pi boots properly. You also need to Enable Camera Module before you can connect the camera.","title":"Prerequisites"},{"location":"setup/hw-setup/#build-instructions","text":"","title":"Build Instructions"},{"location":"setup/hw-setup/#swap-noir-camera-cable","text":"The 6-inch cable that came with the camera is too short. Please replace the short (6-inch) cable with a long (12-inch) cable. You can follow this guide provided by ModMyPi . In short, the NoIR camera has a push/pull tab on the back of the camera, just like the one on the Pi itself: Simply pull the black plastic tab out, remove the short cable and replace it with the long cable (make sure the blue plastic strip is facing up as shown), then push the plastic tab back in to secure the cable.","title":"Swap NoIR Camera Cable"},{"location":"setup/hw-setup/#3d-printed-chassis","text":"Use of our chassis is optional but recommended to prevent young children from touching exposed electronic circuitry. Every cot is different, so our chassis does not include mounting brackets. If you have access to a MakerBot Replicator (5th Generation), you can simply download the .makerbot files for the case and cover onto your MakerBot Replicator and print. If you are using a different type of 3D printer, please keep reading. As mentioned above, printing a baby monitor requires a minimum volume of 9.9 inches (L) x 7.8 inches (W) x 5.9 inches (H). If you don't have a 3D printer with this build volume, you can use an online 3D printing service such as Shapeways or Sculpteo to print the baby monitor. The minimum print resolution is 0.015 inches. If you are using a Fused Filament Manufacturing type 3D printer, this means that your nozzle diameter needs to be 0.015 inches or less. Printers with lower print resolution (larger nozzle diameter) may work, but the Raspberry Pi may not fit in the chassis. We recommend Polylactic Acid (PLA) as the preferred printing material. Other plastics can be used, but if the coefficient of thermal expansion of the chosen plastic is greater than that of PLA, the Raspberry Pi may not fit into the chassis. Before proceeding, download the enclosure and cover 3D files. For instructions on orienting the 3D model in the printer build space, refer to the instruction manual that came with the 3D printer. Examples of chassis and cover mounting orientations are shown below. Case: Cover: In addition to placing the neck of the baby monitor flat on the build plate, you may also notice that the model is rotated around a vertical axis. This may be necessary to load the model into the 3D printer build space. If the build space is long enough to accommodate the baby monitor, rotation is optional.","title":"3D Printed Chassis"},{"location":"setup/hw-setup/#ir-led-circuit","text":"To provide sufficient illumination at night, we use infrared LEDs, which are invisible to the human eye but visible to the NoIR camera. The IR LEDs don't consume much power compared to the Raspberry Pi, so for simplicity we'll leave the IR LEDs on. To power the LEDs through the GPIO pins on the Pi, we built the circuit shown below. Figure: LED Schematic For simplicity and backward compatibility, we use the 5V power pin, which can provide up to 1.5A . According to our measurements, the forward voltage of the infrared LED is about 1.7~1.9V. Although their LED and ASA have a maximum current of 500MA, we decided to reduce the current to around 200MA to reduce heat and overall power consumption. To bridge the gap between 5V and 1.9V, we decided to use three 1N4001 diodes and a 1 ohm resistor in series with the IR LED. Therefore, the voltage across the IR LED is 5V - 0.2V - (3 * 0.9V) - 0.2V = 1.9V . The heat dissipation of each LED is 0.18W, and the heat dissipation of the resistor is 0.2W, both within the maximum ratings. The circuit should looking something like this:","title":"IR LED Circuit"},{"location":"setup/hw-setup/#assembly-bring-it-all-together","text":"Once you have all the hardware ready, you can start assembling. You can use any glue for this process, but we recommend hot glue for two main reasons. Hot glue dries quickly, so you don't need to wait long for the glue to dry. In addition, if you make a mistake, hot glue is removable. To remove dried hot glue, soak the hot glue in in rubbing (isopropyl) alcohol. Make sure everything is dry before reapplying the hot glue and powering up your Raspberry Pi. Throughout the T and build process, check to make sure all T and ports are still accessible through the holes in the int and baby monitor chassis. Insert the Raspberry Pi into the case. Once it is in place, make sure all ports are accessible (e.g., you can plug in the power supply). Next, use some hot glue to secure the Raspberry Pi in place and mount the camera to the Raspberry Pi. There are also screw holes on the Raspberry Pi that you can use if you prefer. ==\u66ff\u6362\u5b9e\u7269\u56fe== Glue the LED and camera to the front cover. ==\u66ff\u6362\u5b9e\u7269\u56fe== First, glue the NoIR camera into the camera hole. Make sure the camera is firmly seated and aligned with the chassis. Do not use too much glue or the camera will not fit into the main case. Always power on the Raspberry Pi and check the camera (e.g., using raspistill -v ) to make sure it is at the right angle and has a good field of view. If the angle is wrong, remove the hot glue and reposition it. ==\u66ff\u6362\u5b9e\u7269\u56fe== Next, glue an infrared LED light to the hole in the neck of the bedspread. It is at a 45-degree angle to the bedspread to illuminate the crib from the side and create more shadows in low-light environments. This will increase the contrast of the image and make it easier to detect motion. ==\u66ff\u6362\u5b9e\u7269\u56fe== After gluing them to the neck, it should look like this: ==\u66ff\u6362\u5b9e\u7269\u56fe== Connect the infrared LED wires to the GPIO pins of the Raspberry Pi as shown in the LED schematic. Place the cable into the chassis, being careful not to wrinkle or strain it. ==\u66ff\u6362\u5b9e\u7269\u56fe== Once everything is tucked in place, hot glue the edges where the two pieces meet to seal them in place. ==\u66ff\u6362\u5b9e\u7269\u56fe==","title":"Assembly: Bring it all together"},{"location":"setup/sw-setup/","text":"Software Setup Guide This is the step-by-step guide on building the video-based baby monitor software on Raspbian/Ubuntu. Prerequisites This software depends on autoconf , libtool , OpenCV and libcanberra . Install these by running NOTE : For compatibility with the project code, Opencv version 2.4 needs to be installed. We provide steps on how to install Opencv version 2.4.13.5 at troubleshooting page . If your environment does not have that version of Opencv, please complete the installation before the Build step. sudo apt-get install git build-essential libtool autoconf libopencv-dev libcanberra-dev Next, you need to add \u2018bcm2835-v4l2\u2019 to /etc/modules-load.d/modules.conf to set the camera driver to autoload. Your modules.conf should look like this: # /etc/modules: kernel modules to load at boot time. # # This file contains the names of kernel modules that should be loaded # at boot time, one per line. Lines beginning with \"#\" are ignored. i2c-dev bcm2835-v4l2 After adding the line and saving the file, reboot the Raspberry Pi . This is the driver for the monitor to acquire frames directly from the NoIR camera. Build To build the software, navigate to the root of the software source directory and run ./autogen.sh --prefix=/usr --sysconfdir=/etc --disable-debug make sudo make install sudo systemctl daemon-reload Usage To start the program in the background: sudo systemctl start babymonitor To run it in the foreground: babymonitor --config /etc/babymonitor/config.ini To start the program automatically at every boot: sudo systemctl enable babymonitor To stop baby monitor from automatically running at boot: sudo systemctl disable babymonitor Note that when babymonitor is started using systemctl , configuration parameters are sent and stored in /etc/systemd/system/babymonitor.service . Once you have installed the software and have it configured well for your setting, you will no longer need the keyboard/mouse/monitor. Now, you can set your baby monitor to autorun at every boot as shown above. Now, all you need to do is plug in the speaker, mount the baby monitor to the side of the cot in the previously tested position, and plug it in. The software will run automatically after a few moments and start tracking movements. However, you can unplug the speaker and let it continue to run (make sure to place the baby in the crib for a few minutes before plugging it back in). Do not unplug the Pi directly, as this may damage the SD card. Keep in mind that you may need to reconfigure if the environment changes. You will need to disable the autorun feature using the above command and complete the calibration steps on the configuration page on the calibration steps. If there are problems, you can check our troubleshooting page Tip : If everything is set up, you can backup the Raspberry Pi SD card for easy restoration in case something goes wrong. Software Configuration The baby monitor can be customised with a simple INI configuration file. After running make install , the configuration file is located at: sudo nano /etc/babymonitor/config.ini and it will look like this [io] ; I/O configuration ; input = vid/noir_cam/lowres_10fps_orange_2min.h264 ; Input file to use input_fps = 15 ; fps of input (40 max, 15 recommended if using camera) full_fps = 4.5 ; fps at which full frames can be processed crop_fps = 15 ; fps at which cropped frames can be processed camera = 0 ; Camera to use width = 640 ; Width of the input video height = 480 ; Height of the input video time_to_alarm = 10 ; How many seconds to wait with no motion before alarm. [cropping] ; Adaptive Cropping Settings crop = true ; Whether or not to crop frames_to_settle = 10 ; # frames to wait after reset before processing roi_update_interval = 800 ; # frames between recalculating ROI roi_window = 50 ; # frames to monitor before selecting ROI [motion] ; Motion Detection Settings erode_dim = 4 ; dimension of the erode kernel dilate_dim = 60 ; dimension of the dilate kernel diff_threshold = 8 ; abs difference needed before recognizing change duration = 1 ; # frames to maintain motion before flagging true pixel_threshold = 5 ; # pixels that must be different to flag as motion show_diff = false ; display the diff between 3 frames [magnification] ; Video Magnification Settings amplify = 25 ; The % amplification desired low-cutoff = 0.5 ; The low frequency of the bandpass. high-cutoff = 1.0 ; The high frequency of the bandpass. threshold = 50 ; The phase threshold as % of pi. show_magnification = false ; Show the output frames of each magnification [debug] print_times = false ; Print analysis times View all configuration details on the Configuration page for full configuration details. Software Architecture Details We saw some video enlargement great demos from MIT and wanted to try running a similar algorithm on a Raspberry Pi. In order to run in real-time on the Pi, the video zoom needs to be about 10 times faster than tbl3rd's great work on its C++ implementation . The required optimisations guided the design of our software. The software that handles the video stream is implemented as a state machine that runs in a loop as shown below. There are currently six states that administer all of our processing steps. Our state machine logic is called each time a new frame is read from the camera. stateDiagram-v2 [*] --> init_st init_st --> monitor_motion_st monitor_motion_st --> compute_roi_st compute_roi_st --> valid_roi_st valid_roi_st --> steady_st steady_st --> reset_st reset_st --> monitor_motion_st Initialization When a video stream is first opened, there is usually a flash of white or black pixels that looks like a lot of motion is occurring. This state simply initialises the video zoom and motion detection code and skips a few frames before jumping to motion monitoring. Monitoring Motion In this state, the complete 640 x 480 frame is zoomed in and the moving pixels between frames are calculated using the image differencing algorithm of Collins et al. The output of this algorithm is a black and white image where white pixels indicate the pixels that have changed. These black-and-white images are then bitwise summed to form a number of frames, thus accumulating the trajectory of the movement during this time. Computing a Region of Interest Accumulated black-and-white frames represent the trajectory of motion over several frames, with slight erosion of the image to remove noise, and then a large zoom in to highlight the areas of most intense motion. Dilation is necessary to merge discrete points into a continuous region of motion. Because of the zoom in, it is easy to find the largest contour in the black and white image that represents the main source of motion and to draw a bounding box around the contour. In this part of the code, we can set the boundaries of the crop size. Steady State This is where we spend most of our software time. In this state, the software runs on cropped frames. Performs video zoom and calculates the amount of movement in the frame. In this state, we were able to process fast enough to catch up with any delays incurred during full-frame processing and keep up with the 10fps video stream. Periodic Reset Since babies may move occasionally, we reset the video zoom and crop periodically so that we can obtain full resolution frames to repeat the process of monitoring motion and finding new regions of interest. All these timing parameters are easily configurable. Technical Challenges Speed When we started this project, our C++ implementation could zoom in on video at 394,000 pixels per second on a Raspberry Pi 3. For reference, this means that our code can only process a 640 x 480 video stream at approximately 1.3 frames per second. Optimising the code for real-time was our primary goal and challenge, as we needed to increase the speed by a factor of 10 to handle at least 10 frames per second. We are now able to process over 1,200,000 pixels per second and use additional cropping to process 10 fps video streams in real time. We used three main optimisations to improve performance by a factor of 10: (1) multithreading, (2) adaptive cropping, and (3) compiler optimisations. Each optimisation is described in detail below. Multithreading (~3x) One of the intuitive and high-value optimisations is to process parts of each video frame in parallel. To do this, we split each frame vertically so that the height of each section is one-third of the original frame. Each section is then zoomed in, as if it were its own video stream. The resulting zoomed frames are then joined together to form a full resolution frame before the motion frames are evaluated. This one optimisation alone increased our processing speed to 938,000 pixels per second (roughly 3 times faster). Three of the Raspberry Pi's four cores are dedicated to video amplification, while the fourth is responsible for control flow and motion processing. Adaptive Cropping (~3x) Multi-threaded techniques aim to increase the number of pixels we can process per second, while adaptive cropping techniques aim to reduce the number of pixels we need to process. Our optimisation is based on two main assumptions. Firstly, the camera's field of view captures the entire cot, with the baby being the only source of motion in the frame. Secondly, the camera should be positioned so that movement can be discerned and the area of interest is no more than one third of the frame. With these assumptions, we can regularly monitor full-frame images to determine where motion is occurring, and then crop the data stream so that it contains only relevant motion. By reducing the number of pixels we process in steady state and amortising the cost of monitoring a few full-resolution frames, we were able to increase the number of frames that could be processed per second by about a factor of three. Compiler Optimizations (~1.2x) Finally, in order to achieve a speedup of more than 10x, we made some optimisations to the code and used additional compiler flags. In particular, we use the -O3 optimisation level and force the compiler to generate vector instructions using -ftree-vectorize and -mfpu=crypto-neon-fp-armv8 . In addition, we need to add the -funsafe-math-optimization flag to enable vector floating-point generation, since NEON instructions are not IEEE compliant or gcc would not generate them. We found that there are two major challenges to implementing compiler optimisation. The first is to expose the operation to the compiler. The most expensive part of the conversion occurs in the two all-pixel loops, but previously each operation in the loops was implemented by calling opencv to run the operation on all pixels. On x86-64 machines, this is already an improvement because the cache is larger and the compiler always issues at least SSE2 vector instructions. In contrast, converting from opencv code, which supports vector instructions, to straight C++ code gives worse performance on the Pi. We recovered the performance degradation by adding compiler flags, but ran into toolchain issues. The Pi 3 comes with an ARM Cortex A53 processor, an A-class 64-bit ARMv8 processor with NEON and cryptographic extensions, but it runs a 32-bit operating system compiled for ARMv7. We first discovered that compiling with -march=native exposes a known but not yet fixed GCC bug. Compiling with -march=armv8 seems to work, but linking with ARMv7 libstdc++ generates ABI-incompatible binaries, leading to stack corruption. On the other hand, from the assembler, it seems feasible to keep the default setting of -march=armv7 and just force the FPU to generate NEON. We also added -mtune=cortex-a53 for better instruction scheduling and better loop unwind counting (enabled in -O3), but we suspect it has no effect because the version of GCC we're using (4.9.2, powered by Raspbian) doesn't recognise it. Profiling In order to identify further optimisation points, profiling was used to determine where the code spent the most time. In the process, we also ran into toolchain issues, as valgrind was unable to emulate the NEON vector instruction and crashed. So we turned to gprof , but we found its timing a bit unreliable, despite the -fno-inline switch (on the other hand, function call counting is accurate, but not very useful). Finally, we tried perf , which uses hardware performance counters to give us instruction-level timing, but we found that it was very accurate inside the conversion code and had zero data outside because it couldn't see samples of other code. Overall, the analysis showed that 96% of the time was spent on transitions, 2% on motion detection, and the rest of the time was spent on threading and locking overheads and accessing the camera. Timing Overall, our algorithm is able to process full 640x480 frames in 220 to 240 milliseconds, while in the worst case scenario after cropping (cropping to about 320x320), our algorithm runs in about 70 milliseconds per frame. This way we can maintain a consistent 10 fps target.","title":"Software Setup Instructions"},{"location":"setup/sw-setup/#software-setup-guide","text":"This is the step-by-step guide on building the video-based baby monitor software on Raspbian/Ubuntu.","title":"Software Setup Guide"},{"location":"setup/sw-setup/#prerequisites","text":"This software depends on autoconf , libtool , OpenCV and libcanberra . Install these by running NOTE : For compatibility with the project code, Opencv version 2.4 needs to be installed. We provide steps on how to install Opencv version 2.4.13.5 at troubleshooting page . If your environment does not have that version of Opencv, please complete the installation before the Build step. sudo apt-get install git build-essential libtool autoconf libopencv-dev libcanberra-dev Next, you need to add \u2018bcm2835-v4l2\u2019 to /etc/modules-load.d/modules.conf to set the camera driver to autoload. Your modules.conf should look like this: # /etc/modules: kernel modules to load at boot time. # # This file contains the names of kernel modules that should be loaded # at boot time, one per line. Lines beginning with \"#\" are ignored. i2c-dev bcm2835-v4l2 After adding the line and saving the file, reboot the Raspberry Pi . This is the driver for the monitor to acquire frames directly from the NoIR camera.","title":"Prerequisites"},{"location":"setup/sw-setup/#build","text":"To build the software, navigate to the root of the software source directory and run ./autogen.sh --prefix=/usr --sysconfdir=/etc --disable-debug make sudo make install sudo systemctl daemon-reload","title":"Build"},{"location":"setup/sw-setup/#usage","text":"To start the program in the background: sudo systemctl start babymonitor To run it in the foreground: babymonitor --config /etc/babymonitor/config.ini To start the program automatically at every boot: sudo systemctl enable babymonitor To stop baby monitor from automatically running at boot: sudo systemctl disable babymonitor Note that when babymonitor is started using systemctl , configuration parameters are sent and stored in /etc/systemd/system/babymonitor.service . Once you have installed the software and have it configured well for your setting, you will no longer need the keyboard/mouse/monitor. Now, you can set your baby monitor to autorun at every boot as shown above. Now, all you need to do is plug in the speaker, mount the baby monitor to the side of the cot in the previously tested position, and plug it in. The software will run automatically after a few moments and start tracking movements. However, you can unplug the speaker and let it continue to run (make sure to place the baby in the crib for a few minutes before plugging it back in). Do not unplug the Pi directly, as this may damage the SD card. Keep in mind that you may need to reconfigure if the environment changes. You will need to disable the autorun feature using the above command and complete the calibration steps on the configuration page on the calibration steps. If there are problems, you can check our troubleshooting page Tip : If everything is set up, you can backup the Raspberry Pi SD card for easy restoration in case something goes wrong.","title":"Usage"},{"location":"setup/sw-setup/#software-configuration","text":"The baby monitor can be customised with a simple INI configuration file. After running make install , the configuration file is located at: sudo nano /etc/babymonitor/config.ini and it will look like this [io] ; I/O configuration ; input = vid/noir_cam/lowres_10fps_orange_2min.h264 ; Input file to use input_fps = 15 ; fps of input (40 max, 15 recommended if using camera) full_fps = 4.5 ; fps at which full frames can be processed crop_fps = 15 ; fps at which cropped frames can be processed camera = 0 ; Camera to use width = 640 ; Width of the input video height = 480 ; Height of the input video time_to_alarm = 10 ; How many seconds to wait with no motion before alarm. [cropping] ; Adaptive Cropping Settings crop = true ; Whether or not to crop frames_to_settle = 10 ; # frames to wait after reset before processing roi_update_interval = 800 ; # frames between recalculating ROI roi_window = 50 ; # frames to monitor before selecting ROI [motion] ; Motion Detection Settings erode_dim = 4 ; dimension of the erode kernel dilate_dim = 60 ; dimension of the dilate kernel diff_threshold = 8 ; abs difference needed before recognizing change duration = 1 ; # frames to maintain motion before flagging true pixel_threshold = 5 ; # pixels that must be different to flag as motion show_diff = false ; display the diff between 3 frames [magnification] ; Video Magnification Settings amplify = 25 ; The % amplification desired low-cutoff = 0.5 ; The low frequency of the bandpass. high-cutoff = 1.0 ; The high frequency of the bandpass. threshold = 50 ; The phase threshold as % of pi. show_magnification = false ; Show the output frames of each magnification [debug] print_times = false ; Print analysis times View all configuration details on the Configuration page for full configuration details.","title":"Software Configuration"},{"location":"setup/sw-setup/#software-architecture-details","text":"We saw some video enlargement great demos from MIT and wanted to try running a similar algorithm on a Raspberry Pi. In order to run in real-time on the Pi, the video zoom needs to be about 10 times faster than tbl3rd's great work on its C++ implementation . The required optimisations guided the design of our software. The software that handles the video stream is implemented as a state machine that runs in a loop as shown below. There are currently six states that administer all of our processing steps. Our state machine logic is called each time a new frame is read from the camera. stateDiagram-v2 [*] --> init_st init_st --> monitor_motion_st monitor_motion_st --> compute_roi_st compute_roi_st --> valid_roi_st valid_roi_st --> steady_st steady_st --> reset_st reset_st --> monitor_motion_st","title":"Software Architecture Details"},{"location":"setup/sw-setup/#initialization","text":"When a video stream is first opened, there is usually a flash of white or black pixels that looks like a lot of motion is occurring. This state simply initialises the video zoom and motion detection code and skips a few frames before jumping to motion monitoring.","title":"Initialization"},{"location":"setup/sw-setup/#monitoring-motion","text":"In this state, the complete 640 x 480 frame is zoomed in and the moving pixels between frames are calculated using the image differencing algorithm of Collins et al. The output of this algorithm is a black and white image where white pixels indicate the pixels that have changed. These black-and-white images are then bitwise summed to form a number of frames, thus accumulating the trajectory of the movement during this time.","title":"Monitoring Motion"},{"location":"setup/sw-setup/#computing-a-region-of-interest","text":"Accumulated black-and-white frames represent the trajectory of motion over several frames, with slight erosion of the image to remove noise, and then a large zoom in to highlight the areas of most intense motion. Dilation is necessary to merge discrete points into a continuous region of motion. Because of the zoom in, it is easy to find the largest contour in the black and white image that represents the main source of motion and to draw a bounding box around the contour. In this part of the code, we can set the boundaries of the crop size.","title":"Computing a Region of Interest"},{"location":"setup/sw-setup/#steady-state","text":"This is where we spend most of our software time. In this state, the software runs on cropped frames. Performs video zoom and calculates the amount of movement in the frame. In this state, we were able to process fast enough to catch up with any delays incurred during full-frame processing and keep up with the 10fps video stream.","title":"Steady State"},{"location":"setup/sw-setup/#periodic-reset","text":"Since babies may move occasionally, we reset the video zoom and crop periodically so that we can obtain full resolution frames to repeat the process of monitoring motion and finding new regions of interest. All these timing parameters are easily configurable.","title":"Periodic Reset"},{"location":"setup/sw-setup/#technical-challenges","text":"","title":"Technical Challenges"},{"location":"setup/sw-setup/#speed","text":"When we started this project, our C++ implementation could zoom in on video at 394,000 pixels per second on a Raspberry Pi 3. For reference, this means that our code can only process a 640 x 480 video stream at approximately 1.3 frames per second. Optimising the code for real-time was our primary goal and challenge, as we needed to increase the speed by a factor of 10 to handle at least 10 frames per second. We are now able to process over 1,200,000 pixels per second and use additional cropping to process 10 fps video streams in real time. We used three main optimisations to improve performance by a factor of 10: (1) multithreading, (2) adaptive cropping, and (3) compiler optimisations. Each optimisation is described in detail below.","title":"Speed"},{"location":"setup/sw-setup/#multithreading-3x","text":"One of the intuitive and high-value optimisations is to process parts of each video frame in parallel. To do this, we split each frame vertically so that the height of each section is one-third of the original frame. Each section is then zoomed in, as if it were its own video stream. The resulting zoomed frames are then joined together to form a full resolution frame before the motion frames are evaluated. This one optimisation alone increased our processing speed to 938,000 pixels per second (roughly 3 times faster). Three of the Raspberry Pi's four cores are dedicated to video amplification, while the fourth is responsible for control flow and motion processing.","title":"Multithreading (~3x)"},{"location":"setup/sw-setup/#adaptive-cropping-3x","text":"Multi-threaded techniques aim to increase the number of pixels we can process per second, while adaptive cropping techniques aim to reduce the number of pixels we need to process. Our optimisation is based on two main assumptions. Firstly, the camera's field of view captures the entire cot, with the baby being the only source of motion in the frame. Secondly, the camera should be positioned so that movement can be discerned and the area of interest is no more than one third of the frame. With these assumptions, we can regularly monitor full-frame images to determine where motion is occurring, and then crop the data stream so that it contains only relevant motion. By reducing the number of pixels we process in steady state and amortising the cost of monitoring a few full-resolution frames, we were able to increase the number of frames that could be processed per second by about a factor of three.","title":"Adaptive Cropping (~3x)"},{"location":"setup/sw-setup/#compiler-optimizations-12x","text":"Finally, in order to achieve a speedup of more than 10x, we made some optimisations to the code and used additional compiler flags. In particular, we use the -O3 optimisation level and force the compiler to generate vector instructions using -ftree-vectorize and -mfpu=crypto-neon-fp-armv8 . In addition, we need to add the -funsafe-math-optimization flag to enable vector floating-point generation, since NEON instructions are not IEEE compliant or gcc would not generate them. We found that there are two major challenges to implementing compiler optimisation. The first is to expose the operation to the compiler. The most expensive part of the conversion occurs in the two all-pixel loops, but previously each operation in the loops was implemented by calling opencv to run the operation on all pixels. On x86-64 machines, this is already an improvement because the cache is larger and the compiler always issues at least SSE2 vector instructions. In contrast, converting from opencv code, which supports vector instructions, to straight C++ code gives worse performance on the Pi. We recovered the performance degradation by adding compiler flags, but ran into toolchain issues. The Pi 3 comes with an ARM Cortex A53 processor, an A-class 64-bit ARMv8 processor with NEON and cryptographic extensions, but it runs a 32-bit operating system compiled for ARMv7. We first discovered that compiling with -march=native exposes a known but not yet fixed GCC bug. Compiling with -march=armv8 seems to work, but linking with ARMv7 libstdc++ generates ABI-incompatible binaries, leading to stack corruption. On the other hand, from the assembler, it seems feasible to keep the default setting of -march=armv7 and just force the FPU to generate NEON. We also added -mtune=cortex-a53 for better instruction scheduling and better loop unwind counting (enabled in -O3), but we suspect it has no effect because the version of GCC we're using (4.9.2, powered by Raspbian) doesn't recognise it.","title":"Compiler Optimizations (~1.2x)"},{"location":"setup/sw-setup/#profiling","text":"In order to identify further optimisation points, profiling was used to determine where the code spent the most time. In the process, we also ran into toolchain issues, as valgrind was unable to emulate the NEON vector instruction and crashed. So we turned to gprof , but we found its timing a bit unreliable, despite the -fno-inline switch (on the other hand, function call counting is accurate, but not very useful). Finally, we tried perf , which uses hardware performance counters to give us instruction-level timing, but we found that it was very accurate inside the conversion code and had zero data outside because it couldn't see samples of other code. Overall, the analysis showed that 96% of the time was spent on transitions, 2% on motion detection, and the rest of the time was spent on threading and locking overheads and accessing the camera.","title":"Profiling"},{"location":"setup/sw-setup/#timing","text":"Overall, our algorithm is able to process full 640x480 frames in 220 to 240 milliseconds, while in the worst case scenario after cropping (cropping to about 320x320), our algorithm runs in about 70 milliseconds per frame. This way we can maintain a consistent 10 fps target.","title":"Timing"},{"location":"setup/troubleshooting/","text":"Troubleshooting Here are some troubleshooting tips we've gathered while making baby monitor. How to install Opencv 2.4 Install dependencies sudo apt-get update sudo apt-get install -y build-essential cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev sudo apt-get install -y python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev Download source code wget -O opencv-2.4.13.5.zip https://github.com/opencv/opencv/archive/2.4.13.5.zip unzip opencv-2.4.13.5.zip cd opencv-2.4.13.5 Create a build directory and configure mkdir build && cd build cmake -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D WITH_FFMPEG=OFF \\ .. Compile and install make -j$(nproc) sudo make install sudo ldconfig Check if installation is complete pkg-config --modversion opencv # Should output 2.4.13.5 No alarm is playing Are your speakers working? Can you play other sounds from the Pi outside of the baby monitor alarm? Is your Pi trying to play audio through HDMI rather than the audio port? Check the Raspberry Pi Audio Configuration page to make sure that you have selected the right output. Is baby monitor detecting motion? Check with journalctl -f to see if baby monitor is running in the background. If it is, perhaps you need to calibrate babymonitor IR LED is not working Can you see a faint red color when you look at the IR LED? A faint red ring should be visible when the LED is on. Check the polarity of the connections. If +5V and GND are reversed, it will not work. Connect the LED to a power supply with a 5V/0.5A voltage/current limit. Normally, it should consume 0.2A at 5V. If it does not, your LED may be malfunctioning. Baby monitor is detecting motion even though there isn't an infant Have you properly configured babymonitor ? Remember, baby monitor is just looking for changes in pixel values Is there a moving shadow within the frame? Is there flickering or changing lighting? Is baby monitor mounted to a stable surface (e.g. something that won't shake if people are walking by it)? Is there any other sources of movement in the frame (mirrors catching reflections, etc)? Baby monitor is NOT detecting motion even though there is motion Have you properly configured babymonitor ? Is there anything in the way of the camera? Are you able to connect to the camera from the Raspberry Pi at all? Check by running raspistill -v in a terminal to open the camera on the Pi for a few seconds. If you look at sudo systemctl status babymonitor , is it actually running? Is your infant under a blanket that is \"tented\" up so that it is not making contact with the child? If there are significant air gaps between the blanket and the child, the blanket may mask the motion. Can you see the motion if you amplify the video more? Can you see the motion if you tune the low and high frequency cutoffs? If this is happening in low-light only, did you make sure your calibration works in low-light? Baby monitor doesn't build Did you install all of the dependencies ? I can't run babymonitor from the commandline Did you accidentally mistype anything when you ran ./autogen.sh --prefix=/usr --sysconfdir=/etc --disable-debug during your software build? Is babymonitor present in /usr/bin/ ?","title":"Troubleshooting"},{"location":"setup/troubleshooting/#troubleshooting","text":"Here are some troubleshooting tips we've gathered while making baby monitor.","title":"Troubleshooting"},{"location":"setup/troubleshooting/#how-to-install-opencv-24","text":"Install dependencies sudo apt-get update sudo apt-get install -y build-essential cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev sudo apt-get install -y python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev Download source code wget -O opencv-2.4.13.5.zip https://github.com/opencv/opencv/archive/2.4.13.5.zip unzip opencv-2.4.13.5.zip cd opencv-2.4.13.5 Create a build directory and configure mkdir build && cd build cmake -D CMAKE_BUILD_TYPE=RELEASE \\ -D CMAKE_INSTALL_PREFIX=/usr/local \\ -D WITH_FFMPEG=OFF \\ .. Compile and install make -j$(nproc) sudo make install sudo ldconfig Check if installation is complete pkg-config --modversion opencv # Should output 2.4.13.5","title":"How to install Opencv 2.4"},{"location":"setup/troubleshooting/#no-alarm-is-playing","text":"Are your speakers working? Can you play other sounds from the Pi outside of the baby monitor alarm? Is your Pi trying to play audio through HDMI rather than the audio port? Check the Raspberry Pi Audio Configuration page to make sure that you have selected the right output. Is baby monitor detecting motion? Check with journalctl -f to see if baby monitor is running in the background. If it is, perhaps you need to calibrate babymonitor","title":"No alarm is playing"},{"location":"setup/troubleshooting/#ir-led-is-not-working","text":"Can you see a faint red color when you look at the IR LED? A faint red ring should be visible when the LED is on. Check the polarity of the connections. If +5V and GND are reversed, it will not work. Connect the LED to a power supply with a 5V/0.5A voltage/current limit. Normally, it should consume 0.2A at 5V. If it does not, your LED may be malfunctioning.","title":"IR LED is not working"},{"location":"setup/troubleshooting/#baby-monitor-is-detecting-motion-even-though-there-isnt-an-infant","text":"Have you properly configured babymonitor ? Remember, baby monitor is just looking for changes in pixel values Is there a moving shadow within the frame? Is there flickering or changing lighting? Is baby monitor mounted to a stable surface (e.g. something that won't shake if people are walking by it)? Is there any other sources of movement in the frame (mirrors catching reflections, etc)?","title":"Baby monitor is detecting motion even though there isn't an infant"},{"location":"setup/troubleshooting/#baby-monitor-is-not-detecting-motion-even-though-there-is-motion","text":"Have you properly configured babymonitor ? Is there anything in the way of the camera? Are you able to connect to the camera from the Raspberry Pi at all? Check by running raspistill -v in a terminal to open the camera on the Pi for a few seconds. If you look at sudo systemctl status babymonitor , is it actually running? Is your infant under a blanket that is \"tented\" up so that it is not making contact with the child? If there are significant air gaps between the blanket and the child, the blanket may mask the motion. Can you see the motion if you amplify the video more? Can you see the motion if you tune the low and high frequency cutoffs? If this is happening in low-light only, did you make sure your calibration works in low-light?","title":"Baby monitor is NOT detecting motion even though there is motion"},{"location":"setup/troubleshooting/#baby-monitor-doesnt-build","text":"Did you install all of the dependencies ?","title":"Baby monitor doesn't build"},{"location":"setup/troubleshooting/#i-cant-run-babymonitor-from-the-commandline","text":"Did you accidentally mistype anything when you ran ./autogen.sh --prefix=/usr --sysconfdir=/etc --disable-debug during your software build? Is babymonitor present in /usr/bin/ ?","title":"I can't run babymonitor from the commandline"}]}